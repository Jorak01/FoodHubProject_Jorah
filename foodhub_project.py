# -*- coding: utf-8 -*-
"""Foodhub_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BCvKsRv0OVNFf8M560pC7ysvvi56Va6c
"""

!pip install pandas
!pip install numpy
!pip install matplotlib
!pip install seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import random

# Step 1.1: Create the data csv
# USE ONLY THIS IF YOU HAVE ALL THE DATA IN A DATASET CSV ALREADY, Also adjust the filepath to your csv

# Define the path to the CSV file
foodhub_orders = 'foodhub_order.csv'

# Check if the file exists and is not empty
if os.path.exists(foodhub_orders) and os.path.getsize(foodhub_orders) > 0:
    # Import CSV file
    data = pd.read_csv(foodhub_orders)
    print(f"Imported data from {foodhub_orders}")
else:
    # Create a blank DataFrame and save it as a CSV file
    data = pd.DataFrame(columns=['order_id', 'customer_id', 'restaurant_name', 'cuisine_type', 'cost_of_the_order', 'day_of_the_week', 'rating', 'food_preparation_time', 'delivery_time'])
    data.to_csv(foodhub_orders, index=False)
    print(f"Created a blank DataFrame and saved it as {foodhub_orders}")

# Print the DataFrame
print(data)

# Step 1.2: Load csv with columns
# ONLY USE FOR CLEARING PURPOSES IF DATASET IS ALREADY FILLED DO NOT USE

data = pd.DataFrame(columns=['order_id', 'customer_id', 'restaurant_name', 'cuisine_type', 'cost_of_the_order', 'day_of_the_week', 'rating', 'food_preparation_time', 'delivery_time'])
data.to_csv(foodhub_orders, index=False)

# Step 1.3: Error Check csv
try:
       data = pd.read_csv('foodhub_orders.csv')
except pd.errors.EmptyDataError:
       print("The CSV file is empty. Creating an empty DataFrame with columns.")
       data = pd.DataFrame(columns=['order_id', 'customer_id', 'restaurant_name', 'cuisine_type', 'cost_of_the_order', 'day_of_the_week', 'rating', 'food_preparation_time', 'delivery_time'])  # Replace with your desired column names

# Step 2.1: Load the dataset
# Read csv Dataset
data = pd.read_csv('foodhub_orders.csv')

# List of columns to plot
columns = data.columns

# Display the first few rows of the dataset
print(data.head())

# Step 3: Data Cleaning and Preprocessing
# Check for missing values
print(data.isnull().sum())

# Drop duplicates if any
data = data.drop_duplicates()

# Step 4: Exploratory Data Analysis
# Basic statistical analysis of each feature
print(data.describe())

# Step 5.1: Graphs and Plots
# Function to create plots based on column type
def create_plots(data, columns):
    for column in columns:
        plt.figure(figsize=(10, 6))

        if data[column].dtype == 'object':
            # Categorical data: Use countplot
            sns.countplot(x=column, data=data, palette='viridis')
            plt.title(f'Distribution of {column.replace("_", " ").title()}')
            plt.xlabel(column.replace("_", " ").title())
            plt.ylabel('Count')

        else:
            # Numerical data: Use histogram
            sns.histplot(data[column], bins=30, kde=True, palette='viridis')
            plt.title(f'Distribution of {column.replace("_", " ").title()}')
            plt.xlabel(column.replace("_", " ").title())
            plt.ylabel('Frequency')
        plt.xticks(rotation=45)
        plt.show()

# Create plots for all columns
create_plots(data, columns)

# Step 5.2: Multivariate analysis

# Multivariate analysis
def multivariate_analysis(data):
    # Select only numeric columns for correlation
    numeric_data = data[['cost_of_the_order', 'rating', 'food_preparation_time', 'delivery_time']].apply(pd.to_numeric, errors='coerce')

    # Correlation matrix
    correlation_matrix = numeric_data.corr()
    print("\nCorrelation Matrix:\n", correlation_matrix)

    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
    plt.title('Correlation Matrix Heatmap')
    plt.show()

    # Scatter plots (using numeric_data now)
    numeric_columns = ['cost_of_the_order', 'rating', 'food_preparation_time', 'delivery_time']
    for i, col1 in enumerate(numeric_columns):
        for col2 in numeric_columns[i+1:]:
            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=col1, y=col2, data=numeric_data) # Use numeric_data
            plt.title(f'Scatter Plot of {col1.replace("_", " ").title()} vs. {col2.replace("_", " ").title()}')
            plt.xlabel(col1.replace("_", " ").title())
            plt.ylabel(col2.replace("_", " ").title())
            plt.show()

    # Group by operations (using original data)
    # Selecting only numeric columns for the mean calculation
    group_by_day = data.groupby('day_of_the_week')[['cost_of_the_order', 'rating', 'food_preparation_time', 'delivery_time']].mean()
    print("\nGroup By Day of the Week (Mean Values):\n", group_by_day)

    plt.figure(figsize=(14, 8))
    group_by_day[['cost_of_the_order', 'rating', 'food_preparation_time', 'delivery_time']].plot(kind='bar', stacked=True)
    plt.title('Mean Values by Day of the Week')
    plt.xlabel('Day of the Week')
    plt.ylabel('Mean Values')
    plt.xticks(rotation=45)
    plt.legend(loc='upper right')
    plt.show()

# Perform multivariate analysis
multivariate_analysis(data)

# Step 6: Conclusion
def conclusion(data):
    print("\nConclusions and Recommendations:")
    print("1. Distribution Insights: The dataset shows varied distribution across different days of the week and various cuisine types.")
    print("2. Correlation Insights: The correlation matrix indicates a strong relationship between food preparation time and delivery time.")
    print("3. Business Insights: Popular restaurants and cuisines can be targeted for promotional activities to boost sales.")
    print("4. Operational Insights: Identifying peak order times on specific days can help optimize staffing and resource allocation.")

conclusion(data)

!jupyter nbconvert --execute --to html "/content/drive/MyDrive/Colab Notebooks/Foodhub_Project.ipynb"